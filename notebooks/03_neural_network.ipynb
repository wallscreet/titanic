{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1081b78",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a620a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3fedf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from src.preprocess import build_preprocessor\n",
    "from src.dataset import TitanicDataset\n",
    "from src.model import TitanicNN\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f913daea",
   "metadata": {},
   "source": [
    "## Build and Save Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016bffa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension after encoding: 34\n"
     ]
    }
   ],
   "source": [
    "preprocessor, cat_cols, num_cols = build_preprocessor('../data/processed/train_clean.csv')\n",
    "input_dim = joblib.load('../models/preprocessor.pkl').transform(\n",
    "    pd.read_csv('../data/processed/train_clean.csv').drop(columns=['Survived'])\n",
    ").shape[1]\n",
    "print(f'Input dimension after encoding: {input_dim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e716995",
   "metadata": {},
   "source": [
    "## Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f987553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = TitanicDataset(\n",
    "    '../data/processed/train_clean.csv',\n",
    "    '../models/preprocessor.pkl',\n",
    "    has_label=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e11c54",
   "metadata": {},
   "source": [
    "## 5-fold CV + early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e4909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Early stop at epoch 18\n",
      "Fold 1 best validation accuracy: 0.9058\n",
      "\n",
      "=== Fold 2 ===\n",
      "Epoch  20 | Train loss 0.3139 | Val acc 0.7713\n",
      "Early stop at epoch 25\n",
      "Fold 2 best validation accuracy: 0.7803\n",
      "\n",
      "=== Fold 3 ===\n",
      "Early stop at epoch 13\n",
      "Fold 3 best validation accuracy: 0.8027\n",
      "\n",
      "=== Fold 4 ===\n",
      "Epoch  20 | Train loss 0.3415 | Val acc 0.8243\n",
      "Early stop at epoch 23\n",
      "Fold 4 best validation accuracy: 0.8423\n",
      "\n",
      "CV mean accuracy: 0.8328 ± 0.0477\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=420)\n",
    "labels = pd.read_csv('../data/processed/train_clean.csv')['Survived']\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(full_dataset)), labels)):\n",
    "    print(f'\\n=== Fold {fold+1} ===')\n",
    "    train_sub = torch.utils.data.Subset(full_dataset, train_idx)\n",
    "    val_sub   = torch.utils.data.Subset(full_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_sub, batch_size=64, shuffle=True)\n",
    "    val_loader   = DataLoader(val_sub,   batch_size=128, shuffle=False)\n",
    "\n",
    "    model = TitanicNN(input_dim).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=6, factor=0.3)\n",
    "\n",
    "    best_val = 0.0\n",
    "    patience, trials = 0, 10\n",
    "\n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for Xb, yb in train_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(Xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # ---- validation ----\n",
    "        model.eval()\n",
    "        val_preds, val_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for Xb, yb in val_loader:\n",
    "                Xb, yb = Xb.to(device), yb.to(device)\n",
    "                val_preds.append(model(Xb).cpu().numpy())\n",
    "                val_true.append(yb.cpu().numpy())\n",
    "        val_preds = np.concatenate(val_preds).squeeze()\n",
    "        val_true  = np.concatenate(val_true).squeeze()\n",
    "        val_acc = ( (val_preds > 0.5) == val_true ).mean()\n",
    "\n",
    "        scheduler.step(1 - val_acc)\n",
    "\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), f'../models/nn_fold{fold+1}_best.pt')\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= trials:\n",
    "                print(f'Early stop at epoch {epoch+1}')\n",
    "                break\n",
    "\n",
    "        if (epoch+1) % 20 == 0:\n",
    "            print(f'Epoch {epoch+1:3d} | Train loss {train_loss/len(train_loader):.4f} | Val acc {val_acc:.4f}')\n",
    "\n",
    "    cv_scores.append(best_val)\n",
    "    print(f'Fold {fold+1} best validation accuracy: {best_val:.4f}')\n",
    "\n",
    "print(f'\\nCV mean accuracy: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36731bd",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952c1cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full-train epoch 20\n",
      "Full-train epoch 40\n",
      "Full-train epoch 60\n",
      "Full-train epoch 80\n",
      "Full-train epoch 100\n",
      "Full-train epoch 120\n",
      "Full-train epoch 140\n",
      "Full-train epoch 160\n",
      "Full-train epoch 180\n",
      "Full-train epoch 200\n",
      "Full-train epoch 220\n",
      "Full-train epoch 240\n",
      "Full-train epoch 260\n",
      "Full-train epoch 280\n",
      "Full-train epoch 300\n",
      "Full-train epoch 320\n",
      "Full-train epoch 340\n",
      "Full-train epoch 360\n",
      "Full-train epoch 380\n",
      "Full-train epoch 400\n",
      "Full-train epoch 420\n"
     ]
    }
   ],
   "source": [
    "# Load best hyper-params (same arch)\n",
    "final_model = TitanicNN(input_dim).to(device)\n",
    "final_model.load_state_dict(torch.load('../models/nn_fold1_best.pt'))  # pick any\n",
    "\n",
    "# Retrain on whole training set\n",
    "full_loader = DataLoader(full_dataset, batch_size=64, shuffle=True)\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=5e-4)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(420):\n",
    "    final_model.train()\n",
    "    for Xb, yb in full_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(final_model(Xb), yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(f'Full-train epoch {epoch+1}')\n",
    "\n",
    "torch.save(final_model.state_dict(), '../models/nn_final.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee534394",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset (no label)\n",
    "test_dataset = TitanicDataset(\n",
    "    '../data/processed/test_clean.csv',\n",
    "    '../models/preprocessor.pkl',\n",
    "    has_label=False\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "final_model.eval()\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for Xb in test_loader:\n",
    "        Xb = Xb.to(device)\n",
    "        test_preds.append(final_model(Xb).cpu().numpy())\n",
    "test_preds = np.concatenate(test_preds).squeeze()\n",
    "\n",
    "submission = pd.read_csv('../data/raw/gender_submission.csv')\n",
    "submission['Survived'] = (test_preds > 0.5).astype(int)\n",
    "\n",
    "os.makedirs('../submissions', exist_ok=True)\n",
    "submission.to_csv('../submissions/nn_v1.csv', index=False)\n",
    "print('Submission saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
